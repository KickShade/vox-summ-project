{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Whisper and its dependencies\n",
        "!pip install pydub\n",
        "!apt-get install ffmpeg  # Required for pydub to handle MP3 files\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4QW-dCrgnmq",
        "outputId": "8b37857c-bd10-4323-b6ff-cad280cfeb9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-gbjrhgeo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-gbjrhgeo\n",
            "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803583 sha256=3db7330e290bd9b6c76c8599bd9953a5eba6268a1c066360f256661ac3970772\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s7i0tq8m/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Whisper and FFMPEG for the ASR and the audio controlling+format changes respectively."
      ],
      "metadata": {
        "id": "8OAXy9SaHZXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Torch and checking if GPU side is all working."
      ],
      "metadata": {
        "id": "2_seoWCPHMf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Verify model loading\n",
        "model = whisper.load_model(\"medium\")\n",
        "print(\"Whisper model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "Zt_F1Ho8i2g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bringing in Whisper and checking if it works."
      ],
      "metadata": {
        "id": "-VSEPJsEHHeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload your file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# File path will be stored as keys in the uploaded dictionary\n",
        "audio_file_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {audio_file_path}\")\n"
      ],
      "metadata": {
        "id": "U5qwHrfAgpAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading the audio files to use the ASR up next."
      ],
      "metadata": {
        "id": "bQnC9dRVHCd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Set up model\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# Define the transcription function\n",
        "def transcribe_audio(audio_file, language):\n",
        "    try:\n",
        "        result = model.transcribe(audio_file, language=language)\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription: {e}\")\n",
        "        return None\n",
        "\n",
        "# Map audio files\n",
        "audio_files = {\n",
        "    \"hin_test_aud.wav\": \"hi\",  # Hindi\n",
        "}\n",
        "\n",
        "# Iterate over the files for transcription\n",
        "for audio_file, lang in audio_files.items():\n",
        "    if not os.path.exists(audio_file):\n",
        "        print(f\"File not found: {audio_file}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing file: {audio_file} (Language: {lang})\")\n",
        "    transcription = transcribe_audio(audio_file, language=lang)\n",
        "\n",
        "    if transcription:\n",
        "        print(f\"Transcription ({lang}):\\n{transcription}\\n\")\n",
        "    else:\n",
        "        print(f\"Failed to transcribe {audio_file}.\\n\")\n"
      ],
      "metadata": {
        "id": "p412_35ph1-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have implementing an ASR(Automatic Speech Recognition) by using Whisper from OpenAI. loading the medium model (can use large if we want to even go further to detect accents and such);\n",
        "\n",
        "Here the language we want is chosen and the audio is converted to text in the desired language (hi=hindi)."
      ],
      "metadata": {
        "id": "PLEauYThF54d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the Hugging Face multilingual model for summarization (mBART) and set device=-1 for CPU usage\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/mbart-large-50-one-to-many-mmt\", tokenizer=\"facebook/mbart-large-50-one-to-many-mmt\", device=-1)  # -1 sets to CPU\n",
        "\n",
        "# Input Hindi text for summarization\n",
        "hindi_text = \"\"\"\n",
        "भारत एक महान देश है, जिसमें बहुत सारी भाषाएँ, संस्कृतियाँ, और धर्म हैं। यहाँ की ऐतिहासिक धरोहर और सांस्कृतिक विविधता को देखने के लिए दुनियाभर से लोग आते हैं। भारतीय समाज में विविधता है, और हर राज्य की अपनी अलग पहचान है। भारतीय राजनीति, समाज और अर्थव्यवस्था ने बहुत से परिवर्तन देखे हैं। इस देश की प्रगति के लिए मेहनत और शिक्षा महत्वपूर्ण हैं।\n",
        "\"\"\"\n",
        "\n",
        "# Summarize the Hindi text\n",
        "summary = summarizer(hindi_text, max_length=30, min_length=20, do_sample=False)\n",
        "\n",
        "# Output the summary\n",
        "print(\"Summarized Hindi Text:\", summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "id": "c5jCY_qE4alB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing the Hindi text using mBART"
      ],
      "metadata": {
        "id": "CBZToe6vFwor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the Hugging Face translation model for Hindi to English\n",
        "translator = pipeline(\"translation_xx_to_yy\", model=\"Helsinki-NLP/opus-mt-hi-en\", device=-1)\n",
        "\n",
        "# Example input Hindi text (from your summary)\n",
        "input_text = \"भारत एक महान देश है, जिसमें बहुत सारी भाषाएँ, संस्कृतियाँ, और धर्म हैं। यहाँ की ऐतिहासिक धरोहर और सांस्कृतिक है\"\n",
        "\n",
        "# Translate the summarized Hindi text to English\n",
        "translated_text = translator(input_text)\n",
        "\n",
        "# Display the translated text\n",
        "print(\"Translated Text:\", translated_text[0]['translation_text'])\n"
      ],
      "metadata": {
        "id": "dMIq4rWnANf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing translation of the received summary from Hindi to English by using Helsinki-NLP from hugging face."
      ],
      "metadata": {
        "id": "Na8b7w-sFAq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the sentiment-analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# English translated text (from previous translation step)\n",
        "english_text = \"India is a great country with many languages, cultures, and religions. People come from all over the world to see its historical heritage and cultural diversity. Indian society is diverse, and each state has its own identity. Indian politics, society, and economy have seen many changes. Hard work and education are essential for the progress of this country.\"\n",
        "\n",
        "# Apply sentiment analysis to the English text\n",
        "sentiment = sentiment_analyzer(english_text)\n",
        "\n",
        "# Print the sentiment result\n",
        "print(\"Sentiment Analysis Result:\", sentiment)\n"
      ],
      "metadata": {
        "id": "KppzHHDcD9ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are performing the sentiment analysis using the huggingface's pre trained model."
      ],
      "metadata": {
        "id": "lwHruU6UEuH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sentiment analysis result\n",
        "sentiment_result = {'label': 'POSITIVE', 'score': 0.9996817111968994}\n",
        "\n",
        "# Prepare data for plotting\n",
        "labels = ['POSITIVE', 'NEGATIVE', 'NEUTRAL']\n",
        "scores = [sentiment_result['score'], 1 - sentiment_result['score'], 0]\n",
        "\n",
        "# Create a bar chart for sentiment visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, scores, color=['green', 'red', 'gray'])\n",
        "plt.title('Sentiment Analysis Visualization')\n",
        "plt.xlabel('Sentiment Label')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vIamYYOMEfac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here now we are trying visualize the sentiment analysis result with a graph"
      ],
      "metadata": {
        "id": "Em9a0qRYEhAL"
      }
    }
  ]
}